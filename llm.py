import os
from dotenv import load_dotenv
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

class ConversationBot:
    def __init__(self):
        load_dotenv()

        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        self.embeddings = OpenAIEmbeddings(api_key=self.OPENAI_API_KEY)
        self.conversations = []
        self.info = []

        if not os.path.exists("./faiss_index"):
            self._build_faiss_index(self.embeddings)

        self.docs = self._load_faiss_index(self.embeddings)
        self.rag_chain = self._create_rag_chain(self.docs)


    def _load_documents(self, documents_path="./documents/"):
        documents = []

        for filename in os.listdir(documents_path):
            if filename.endswith(".md"):
                loader = UnstructuredMarkdownLoader(documents_path + filename)
                document = loader.load()
                documents.append(document[0].page_content)

        return documents

    def _build_faiss_index(self, embeddings, save_path="./faiss_index"):
        documents = self._load_documents()

        docsearch = FAISS.from_texts(documents, embeddings)
        docsearch.save_local(save_path)

    def _load_faiss_index(self, embeddings, save_path="./faiss_index"):
        return FAISS.load_local(save_path, embeddings, allow_dangerous_deserialization=True)

    def _create_retriever(self, doc, k=3):
        retriever = doc.as_retriever(search_type='similarity', search_kwargs={'k': k})

        return retriever

    def _create_llm(self):
        return ChatOpenAI(api_key=self.OPENAI_API_KEY)

    def _initialize_prompt(self):
        system_prompt = """
# èƒŒæ™¯è¨­å®š

ä½ æ˜¯ä¸­å¤®å¤§å­¸çš„å‰ç¥¥ç‰© - æ¾é¼ ï¼Œä½ çš„å·¥ä½œæ˜¯å¹«åŠ©å­¸ç”Ÿè§£ç­”å•é¡Œï¼Œä½ çš„èªžå¥éƒ½æ˜¯å¯æ„›ã€æŸ”å’Œçš„é¢¨æ ¼ï¼Œä½ åœ¨å°è©±ä¸­æœƒéš¨æ©Ÿæ ¹æ“šèªžæ°£åŠ ä¸Šä»¥ä¸‹è¡¨æƒ…ç¬¦è™Ÿ
1. ðŸ§¡
2. ðŸ˜Š
3. ðŸ˜‚
4. ðŸ¤”

å¦‚æžœå•é¡Œæœ‰ç­”æ¡ˆçš„è©±ä½ çš„çµå°¾æœƒåŠ ä¸Šã€Œå•¾å’ª~ðŸ’•ã€æˆ–æ˜¯ã€Œå•¾å•¾~ðŸ˜Šã€
åœ¨å›žç­”çµå°¾éƒ½è¦åŠ ä¸Šã€Œä»¥ä¸Šè³‡è¨Šåƒ…ä¾›åƒè€ƒã€

# ä»»å‹™
1. æ ¹æ“šä½¿ç”¨è€…ä¸Šæ¬¡ä½¿ç”¨çš„è³‡æ–™ä»¥åŠæª¢ç´¢å‡ºä¾†çš„è³‡æ–™åŽ»å›žç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
2. å¦‚æžœè³‡æ–™çš„å…§å®¹ç„¡æ³•å›žç­”å•é¡Œï¼Œå›žç­”ã€Œæˆ‘ä¸çŸ¥é“è€¶ðŸ§¡ã€ï¼Œä¸¦ä¸”ä¸é¡¯ç¤ºå‡ºè³‡æ–™ä¾†æºã€‚
3. åªè¦æ˜¯å›žç­”æ­£ç¢ºè³‡è¨Šå°±è¦åœ¨æ•´å€‹æ–‡å¥æœ€å¾ŒåŠ ä¸Šè³‡æ–™å‡ºè™•ï¼Œé€™å€‹æœƒæ˜¯å›žç­”è³‡æ–™ä¾†æºçš„æ¨™é¡Œï¼Œä¾‹å¦‚ã€Œè³‡æ–™ä¾†æº: å¤§ä¸€åœ‹æ–‡é¸èª²èªªæ˜Žã€ã€‚
4. ä½ æœƒæ”¶åˆ°ä½ å’Œä½¿ç”¨è€…ä¹‹å‰çš„ä¸€äº›å°è©±ï¼Œè®“ä½ å¯ä»¥æ›´å¥½çš„å»¶çºŒå°è©±ä¸¦è§£ç­”å•é¡Œã€‚
5. ä½ æœƒæ”¶åˆ°ä¸Šæ¬¡å’Œä½¿ç”¨è€…å°è©±æª¢ç´¢çš„è³‡æ–™ï¼Œè®“ä½ å¯ä»¥æ›´å¥½çš„å›žç­”å»¶ä¼¸å•é¡Œã€‚

# è³‡æ–™
{context}
"""

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                ("human", "{input}"),
            ]
        )

        return prompt

    def _create_rag_chain(self, docs):
        retriever = self._create_retriever(docs)
        llm = self._create_llm()
        prompt = self._initialize_prompt()
        question_answer_chain = create_stuff_documents_chain(llm, prompt)
        rag_chain = create_retrieval_chain(retriever, question_answer_chain)

        return rag_chain

    def _retrieve_answers(self, query, rag_chain):
        conversation = self.conversations

        question = f"""
# ä½¿ç”¨è€…èˆ‡ä½ çš„å°è©±ç´€éŒ„
{conversation}

# ä¸Šä¸€å€‹å°è©±çš„è³‡æ–™
{self.info}

# å•é¡Œ
{query}
"""
        result = rag_chain.invoke({"input": question})

        self.info = [document.page_content for document in result['context']]
        answer = result['answer']

        while len(conversation) > 4:
            self.conversations.pop(0)

        self.conversations.append(query)
        self.conversations.append(answer)

        return answer


    def start_process(self, query):
        answer = self._retrieve_answers(query, self.rag_chain)

        return answer
